---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a first-year Ph.D student at the [School of Computer Science, Wuhan University](https://cs.whu.edu.cn/), advised by [Prof. Bo Du](https://scholar.google.com/citations?user=Shy1gnMAAAAJ&hl=zh-CN) and [Prof. Juhua Liu](https://scholar.google.com/citations?user=wN-rIgIAAAAJ&hl=zh-CN). I work closely with [Dr. Jing Zhang](https://scholar.google.com/citations?user=9jH5v74AAAAJ&hl=zh-CN). I previously interned at JD Explore Academy and iFLYTEK Research.

My research interest includes Computer Vision, Large Language Model, and Multimodal Large Language Model. I previously focused on Optical Character Recognition (OCR) related topics. Now, my research interest lies in Multimodal Large Language Model. In addition, I closely follow the latest developments in Large Language Model.


# üî• News
- *2024.09*: &nbsp;üéâüéâ One paper about video text spotting is accepted by **NeurIPS 2024**. 


# üìù Publications 

\* : Co-first author

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv preprint</div><img src='images/hisam.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Hi-SAM: Marrying Segment Anything Model for Hierarchical Text Segmentation](https://arxiv.org/abs/2401.17904)

**Maoyuan Ye**, Jing Zhang,  Juhua Liu, Chenyu Liu, Baocai Yin, Cong Liu, Bo Du, Dacheng Tao

[**Project**](https://github.com/ymy-k/Hi-SAM)  <a href="https://github.com/ymy-k/Hi-SAM"><img src="https://img.shields.io/github/stars/ymy-k/Hi-SAM.svg?logo=github&label=Stars"></a>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/gomatching.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[GoMatching: A Simple Baseline for Video Text Spotting via Long and Short Term Matching](https://arxiv.org/abs/2401.07080) (**NeurIPS 2024**)

Haibin He\*, **Maoyuan Ye**\*, Jing Zhang,  Juhua Liu, Bo Du, Dacheng Tao

[**Project**](https://github.com/Hxyz-123/GoMatching)  <a href="https://github.com/Hxyz-123/GoMatching"><img src="https://img.shields.io/github/stars/Hxyz-123/GoMatching.svg?logo=github&label=Stars"></a>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv preprint</div><img src='images/deepsolo++.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DeepSolo++: Let Transformer Decoder with Explicit Points Solo for Multilingual Text Spotting](https://arxiv.org/abs/2305.19957)

**Maoyuan Ye**\*, Jing Zhang\*, Shanshan Zhao, Juhua Liu, Tongliang Liu, Bo Du, Dacheng Tao

[**Project**](https://github.com/ViTAE-Transformer/DeepSolo)  <a href="https://github.com/ViTAE-Transformer/DeepSolo"><img src="https://img.shields.io/github/stars/ViTAE-Transformer/DeepSolo.svg?logo=github&label=Stars"></a>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/deepsolo.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text Spotting](https://arxiv.org/abs/2211.10772) (**CVPR 2023**)

**Maoyuan Ye**\*, Jing Zhang\*, Shanshan Zhao, Juhua Liu, Tongliang Liu, Bo Du, Dacheng Tao

[**Project**](https://github.com/ViTAE-Transformer/DeepSolo)  <a href="https://github.com/ViTAE-Transformer/DeepSolo"><img src="https://img.shields.io/github/stars/ViTAE-Transformer/DeepSolo.svg?logo=github&label=Stars"></a>
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2023</div><img src='images/dptext_detr.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in Transformer](https://arxiv.org/abs/2207.04491) (**AAAI 2023, Oral**)

**Maoyuan Ye**, Jing Zhang, Shanshan Zhao, Juhua Liu, Bo Du, Dacheng Tao

[**Project**](https://github.com/ymy-k/DPText-DETR)   <a href="https://github.com/ymy-k/DPText-DETR"><img src="https://img.shields.io/github/stars/ymy-k/DPText-DETR.svg?logo=github&label=Stars"></a>
</div>
</div>



# üíª Internships
- *2023.07 - 2024.02*, iFLYTEK Research, IFLYTEK CO. LTD., China.
- *2022.02 - 2023.06*, JD Explore Academy, JD Inc., China.

# üìñ Academic Service
- Conference Reviewer: CVPR, AAAI, ACM MM.
- Journal Reviewer: IEEE TPAMI, IJCV, TIP.